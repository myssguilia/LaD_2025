{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18936c3",
   "metadata": {},
   "source": [
    "### I WAS NOT ABLE TO RUN THIS NOTEBOOK ON MY COMPUTER. I HAD EVERYTHING INSTALLED CORRECTLY BUT IT WAS TAKING 5 MINUTES TO CLASSIFY 10 UTTERANCES. NEEDLESS TO SAY, IT WAS GOING TO BE IMPOSSIBILE FOR ALL 190 UTTERANCES. \n",
    "I RAN THIS NOTEBOOK ON ANOTHER COMPUTER, TO WHICH I DID NOT HAVE UNLIMITED ACCESS. THIS IS ALL I COULD MANAGE TO DO.\n",
    "\n",
    "I WILL STILL ATTACH TO DELIVERABLES MY NOTEBOOK WHERE I TRIED TO RUN THE MODEL MULTIPLE TIMES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bacdc5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24c3b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_act_labels = [\n",
    "    \"QUESTION\",\n",
    "    \"ANSWER\",\n",
    "    \"ACKNOWLEDGEMENT\", \"BACKCHANNEL\",\n",
    "    \"DIRECTIVE\", \"REQUEST\",\n",
    "    \"REPAIR\", \"CLARIFICATION\",\n",
    "    \"EXPRESSIVE\", \"EMOTIVE\",\n",
    "    \"APOLOGY\",\n",
    "    \"GREETING\",\n",
    "    \"GOODBYE\", \"CLOSING\",\n",
    "    \"OTHER\"\n",
    "]\n",
    "\n",
    "examples = [\n",
    "    {'INPUT': 'we just ↑remi[NISCE]', 'OUTPUT': 'STATEMENT'},\n",
    "    {'INPUT': '((laughs))', 'OUTPUT': 'OTHER'},\n",
    "    {'INPUT': '[that- that is (.)] tr[ue]', 'OUTPUT': 'ACKNOWLEDGMENT'},\n",
    "    {'INPUT': '°yeah°', 'OUTPUT': 'BACKCHANNEL'},\n",
    "    {'INPUT': '°that was a good one°', 'OUTPUT': 'EXPRESSIVE'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3ba5bc",
   "metadata": {},
   "source": [
    "## Prompt try 1\n",
    "\n",
    "I started out with Piek's code (HLT - 2025). I simply adjusted labels and instructions according to this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f111b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMAnnotator:\n",
    "    \n",
    "    def __init__(self, model=\"qwen3:1.7b\", labels=annotation_act_labels, examples=[], max_context=2):\n",
    "        self._client = ChatOllama(\n",
    "            model=model,\n",
    "            think=False,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        self._max_context = max_context\n",
    "        self._history = []\n",
    "        self._instruct = []\n",
    "        self.create_label_instruct(labels, examples)\n",
    "\n",
    "    def create_label_instruct(self, labels=[], examples=[]):\n",
    "        self._instruct = [{\"role\": \"system\", \"content\": \"You are an expert annotator trained in Conversation Analysis and Dialogue Act tagging.\"}]\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"You must assign exactly ONE dialogue act label to EACH utterance.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": 'Utterances use JEFFERSON TRANSCRIPTION. Use them as cues for emotion, repair, overlap, etc., but do NOT treat them as words.'})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"You must classify only the last utterance, using previous utterances only as context.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"Output exactly one label in JSON format with the field 'label'. Do not output anything else.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": f\"Only use one of the following labels: {labels}\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"Use preceding utterances as context.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"Output the most appropriate label in JSON format.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"Do not output anything else.\"})\n",
    "        if examples:\n",
    "            self._instruct.append({\"role\": \"system\", \"content\": \"Here are a few examples:\"})\n",
    "            for example in examples:\n",
    "                self._instruct.append({\"role\": \"user\", \"content\": example[\"INPUT\"]})\n",
    "                self._instruct.append({\"role\": \"system\", \"content\": example[\"OUTPUT\"]})\n",
    "\n",
    "    def annotate_conversation(self, input=[]):\n",
    "        annotations = []\n",
    "        for utterance in input:\n",
    "            annotation = self.annotate(utterance)\n",
    "            annotations.append(annotation)\n",
    "        return annotations\n",
    "\n",
    "    def annotate(self, utterance):\n",
    "        self._history.append({\"role\": \"user\", \"content\": f\"INPUT: {utterance}\"})\n",
    "\n",
    "        if len(self._history) > self._max_context:\n",
    "            self._history = self._history[1:]\n",
    "\n",
    "        prompt = self._instruct + self._history\n",
    "        response = self._client.invoke(prompt)\n",
    "\n",
    "        # Prendi solo il contenuto testuale\n",
    "        answer = response.content\n",
    "\n",
    "        # Rimuovi eventuale <think> tag\n",
    "        end_of_think = answer.find(\"</think>\")\n",
    "        if end_of_think > 0:\n",
    "            answer = answer[end_of_think+8:]\n",
    "\n",
    "        answer = answer.strip()  # pulito da spazi a inizio/fine\n",
    "\n",
    "        return {\"INPUT\": utterance, \"OUTPUT\": answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d471cddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('solo_frasi.txt', 'r') as infilez:\n",
    "    all_file = infilez.read()\n",
    "all_file = all_file.split('\\n')\n",
    "len(all_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf4211ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'INPUT': 'we just â†‘remi[NISCE]', 'OUTPUT': '{\"label\": \"EXPRESSIVE\"}'}\n",
      "{'INPUT': '[remi]nisce', 'OUTPUT': '{\"label\": \"EXPRESSIVE\"}'}\n",
      "{'INPUT': '[eh]', 'OUTPUT': '{\"label\": \"EXPRESSIVE\"}'}\n",
      "{'INPUT': '(a)[bout] a shared memory', 'OUTPUT': '{\"label\": \"EXPRESSIVE\"}'}\n",
      "{'INPUT': \"'kay\", 'OUTPUT': '{\"label\": \"EXPRESSIVE\"}'}\n",
      "{'INPUT': 'm::h hhh ((tsk))', 'OUTPUT': '{\"label\": \"BACKCHANNEL\"}'}\n",
      "{'INPUT': 'which memory would you like', 'OUTPUT': '{\"label\": \"QUESTION\"}'}\n",
      "{'INPUT': \"but i'm tryin' to think which memory is (0.6) within five minutes because they're all short (.) cute moments\", 'OUTPUT': '{\"label\": \"QUESTION\"}'}\n",
      "{'INPUT': 'mh=yea:h', 'OUTPUT': '{\"label\": \"CLARIFICATION\"}'}\n",
      "{'INPUT': \"Â°we- we'll probably spend more than five minutes finding a memoryÂ°\", 'OUTPUT': '{\"label\": \"DIRECTIVE\"}'}\n"
     ]
    }
   ],
   "source": [
    "llm_annotator  = LLMAnnotator(labels=annotation_act_labels, examples=examples, max_context=2)\n",
    "annotations = llm_annotator.annotate_conversation(all_file[:10])\n",
    "for annotation in annotations:\n",
    "    print(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c715799",
   "metadata": {},
   "source": [
    "## Prompt try 2\n",
    "\n",
    "self_history edit > a little better but first labels are still non sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5634a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMAnnotator:\n",
    "    \n",
    "    def __init__(self, model=\"qwen3:1.7b\", labels=annotation_act_labels, examples=[], max_context=2):\n",
    "        self._client = ChatOllama(\n",
    "            model=model,\n",
    "            think=False,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        self._max_context = max_context\n",
    "        self._history = []\n",
    "        self._instruct = []\n",
    "        self.create_label_instruct(labels, examples)\n",
    "\n",
    "    def create_label_instruct(self, labels=[], examples=[]):\n",
    "        self._instruct = [{\"role\": \"system\", \"content\": \"You are an expert annotator trained in Conversation Analysis and Dialogue Act tagging.\"}]\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"You must assign exactly ONE dialogue act label to EACH utterance.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": 'Utterances use JEFFERSON TRANSCRIPTION. Use them as cues for emotion, repair, overlap, etc., but do NOT treat them as words.'})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"You must classify only the last utterance, using previous utterances only as context.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"Output exactly one label in JSON format with the field 'label'. Do not output anything else.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": f\"Only use one of the following labels: {labels}\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"Use preceding utterances as context.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"Output the most appropriate label in JSON format.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"Do not output anything else.\"})\n",
    "        if examples:\n",
    "            self._instruct.append({\"role\": \"system\", \"content\": \"Here are a few examples:\"})\n",
    "            for example in examples:\n",
    "                self._instruct.append({\"role\": \"user\", \"content\": example[\"INPUT\"]})\n",
    "                self._instruct.append({\"role\": \"system\", \"content\": example[\"OUTPUT\"]})\n",
    "\n",
    "    def annotate_conversation(self, input=[]):\n",
    "        annotations = []\n",
    "        for utterance in input:\n",
    "            annotation = self.annotate(utterance)\n",
    "            annotations.append(annotation)\n",
    "        return annotations\n",
    "\n",
    "    def annotate(self, utterance):\n",
    "        self._history.append({\"role\": \"user\", \"content\": utterance})\n",
    "\n",
    "        if len(self._history) > self._max_context:\n",
    "            self._history = self._history[1:]\n",
    "\n",
    "        prompt = self._instruct + self._history\n",
    "        response = self._client.invoke(prompt)\n",
    "\n",
    "        # Prendi solo il contenuto testuale\n",
    "        answer = response.content\n",
    "\n",
    "        # Rimuovi eventuale <think> tag\n",
    "        end_of_think = answer.find(\"</think>\")\n",
    "        if end_of_think > 0:\n",
    "            answer = answer[end_of_think+8:]\n",
    "\n",
    "        answer = answer.strip()  # pulito da spazi a inizio/fine\n",
    "\n",
    "        return {\"INPUT\": utterance, \"OUTPUT\": answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80cde34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'INPUT': 'we just â†‘remi[NISCE]', 'OUTPUT': '{\"label\": \"EXPRESSIVE\"}'}\n",
      "{'INPUT': '[remi]nisce', 'OUTPUT': '{\"label\": \"EXPRESSIVE\"}'}\n",
      "{'INPUT': '[eh]', 'OUTPUT': '{\"label\": \"ACKNOWLEDGEMENT\"}'}\n",
      "{'INPUT': '(a)[bout] a shared memory', 'OUTPUT': '{\"label\": \"EMOTIVE\"}'}\n",
      "{'INPUT': \"'kay\", 'OUTPUT': '{\"label\": \"REPAIR\"}'}\n",
      "{'INPUT': 'm::h hhh ((tsk))', 'OUTPUT': '{\\n  \"label\": \"ACKNOWLEDGEMENT\"\\n}'}\n",
      "{'INPUT': 'which memory would you like', 'OUTPUT': '{\"label\": \"QUESTION\"}'}\n",
      "{'INPUT': \"but i'm tryin' to think which memory is (0.6) within five minutes because they're all short (.) cute moments\", 'OUTPUT': '{\"label\": \"CLARIFICATION\"}'}\n",
      "{'INPUT': 'mh=yea:h', 'OUTPUT': '{\"label\": \"CLARIFICATION\"}'}\n",
      "{'INPUT': \"Â°we- we'll probably spend more than five minutes finding a memoryÂ°\", 'OUTPUT': '{\"label\": \"DIRECTIVE\"}'}\n"
     ]
    }
   ],
   "source": [
    "llm_annotator  = LLMAnnotator(labels=annotation_act_labels, examples=examples, max_context=2)\n",
    "annotations = llm_annotator.annotate_conversation(all_file[:10])\n",
    "for annotation in annotations:\n",
    "    print(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb819a",
   "metadata": {},
   "source": [
    "## Prompt try 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b92594",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMAnnotator:\n",
    "    \n",
    "    def __init__(self, model=\"qwen3:1.7b\", labels=annotation_act_labels, examples=[], max_context=2):\n",
    "        self._client = ChatOllama(\n",
    "            model=model,\n",
    "            think=False,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        self._max_context = max_context\n",
    "        self._history = []\n",
    "        self._instruct = []\n",
    "        self.create_label_instruct(labels, examples)\n",
    "\n",
    "    def create_label_instruct(self, labels=[], examples=[]):\n",
    "        self._instruct = [{\"role\": \"system\", \"content\": \"You are an expert annotator trained in Conversation Analysis and Dialogue Act tagging.\"}]\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"You must assign exactly ONE dialogue act label to EACH utterance.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": 'Utterances use JEFFERSON TRANSCRIPTION. Use them as cues for emotion, repair, overlap, etc., but do NOT treat them as words.'})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"You must classify only the last utterance, using previous utterances only as context.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"Output exactly one label in JSON format with the field 'label'. Do not output anything else.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": f\"Only use one of the following labels: {labels}\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"Use preceding utterances as context.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"Output the most appropriate label in JSON format.\"})\n",
    "        self._instruct.append({\"role\": \"system\", \"content\": \"Do not output anything else.\"})\n",
    "        if examples:\n",
    "            self._instruct.append({\"role\": \"system\", \"content\": \"Here are a few examples:\"})\n",
    "            for example in examples:\n",
    "                self._instruct.append({\"role\": \"user\", \"content\": example[\"INPUT\"]})\n",
    "                self._instruct.append({\"role\": \"system\", \"content\": example[\"OUTPUT\"]})\n",
    "\n",
    "    def annotate_conversation(self, input=[]):\n",
    "        annotations = []\n",
    "        for utterance in input:\n",
    "            annotation = self.annotate(utterance)\n",
    "            annotations.append(annotation)\n",
    "        return annotations\n",
    "\n",
    "    def annotate(self, utterance):\n",
    "        self._history.append({\"role\": \"user\", \"content\": utterance})\n",
    "\n",
    "        if len(self._history) > self._max_context:\n",
    "            self._history = self._history[1:]\n",
    "\n",
    "        prompt = self._instruct + self._history\n",
    "        response = self._client.invoke(prompt)\n",
    "\n",
    "        # Prendi solo il contenuto testuale\n",
    "        answer = response.content\n",
    "\n",
    "        # Rimuovi eventuale <think> tag\n",
    "        end_of_think = answer.find(\"</think>\")\n",
    "        if end_of_think > 0:\n",
    "            answer = answer[end_of_think+8:]\n",
    "\n",
    "        answer = answer.strip()  # pulito da spazi a inizio/fine\n",
    "\n",
    "        return {\"INPUT\": utterance, \"OUTPUT\": answer}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
